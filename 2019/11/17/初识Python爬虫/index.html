<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>初识Python爬虫 | fans的个人博客</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1.1 网络连接当我们浏览一个网页时，所看到的画面是适合用户的，一个网页也是由一段代码编写的，当要查看网页源代码时，可以鼠标右键点击查看源代码进行查看。  让我们来看看Python是如何实现的：  123form urllib.request import urlopen	#查找Python的requset模块（在urllib库中），只导入一个urlopen函数html = urlopen(&amp;qu">
<meta name="keywords" content="Python爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="初识Python爬虫">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;11&#x2F;17&#x2F;%E5%88%9D%E8%AF%86Python%E7%88%AC%E8%99%AB&#x2F;index.html">
<meta property="og:site_name" content="fans的个人博客">
<meta property="og:description" content="1.1 网络连接当我们浏览一个网页时，所看到的画面是适合用户的，一个网页也是由一段代码编写的，当要查看网页源代码时，可以鼠标右键点击查看源代码进行查看。  让我们来看看Python是如何实现的：  123form urllib.request import urlopen	#查找Python的requset模块（在urllib库中），只导入一个urlopen函数html = urlopen(&amp;qu">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-11-17T04:03:59.824Z">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="fans的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="https://www.duitang.com/blog/?id=888975090">
  
  <link rel="stylesheet" href="/css/style.css">
  
  

  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
</head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://www.duitang.com/blog/?id=888975090" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">fans</a></h1>
		</hgroup>

		
		<p class="header-subtitle">欢迎你</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/tags/%E9%9A%8F%E7%AC%94">随笔</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/fans1270/fans1270.github.io" title="github">github</a>
					        
								<a class="mail" target="_blank" href="/fans1270@gmail.com" title="mail">mail</a>
					        
								<a class="qq" target="_blank" href="/1193562011" title="qq">qq</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Python%E7%88%AC%E8%99%AB/" style="font-size: 20px;">Python爬虫</a> <a href="/tags/%E4%B8%AA%E4%BA%BA/" style="font-size: 10px;">个人</a>
					</div>
				</section>
				
				
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">fans</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="https://www.duitang.com/blog/?id=888975090" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">fans</h1>
			</hgroup>
			
			<p class="header-subtitle">欢迎你</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/tags/%E9%9A%8F%E7%AC%94">随笔</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/fans1270/fans1270.github.io" title="github">github</a>
			        
						<a class="mail" target="_blank" href="/fans1270@gmail.com" title="mail">mail</a>
			        
						<a class="qq" target="_blank" href="/1193562011" title="qq">qq</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-初识Python爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/11/17/%E5%88%9D%E8%AF%86Python%E7%88%AC%E8%99%AB/" class="article-date">
  	<time datetime="2019-11-17T01:39:12.000Z" itemprop="datePublished">2019-11-17</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      初识Python爬虫
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python%E7%88%AC%E8%99%AB/" rel="tag">Python爬虫</a></li></ul>
	</div>

        

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-1-网络连接"><a href="#1-1-网络连接" class="headerlink" title="1.1 网络连接"></a>1.1 网络连接</h2><p>当我们浏览一个网页时，所看到的画面是适合用户的，一个网页也是由一段代码编写的，当要查看网页源代码时，可以鼠标右键点击查看源代码进行查看。</p>
<blockquote>
<p>让我们来看看Python是如何实现的：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">form urllib.request import urlopen	#查找Python的requset模块（在urllib库中），只导入一个urlopen函数</span><br><span class="line">html = urlopen(&quot;http://pythonscraping.com/pages/page1.html&quot;)</span><br><span class="line">print(html.read())</span><br></pre></td></tr></table></figure>

<blockquote>
<p>你可以把这段代码保存为 scrapetest.py，然后在终端里运行如下命令：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$python3 scrapetest.py</span><br></pre></td></tr></table></figure>

<p>这将会输出 <a href="http://pythonscraping.com/pages/page1.html" target="_blank" rel="noopener">http://pythonscraping.com/pages/page1.html</a> 这个网页的全部 HTML 代码。更准确地说，这会输出在域名为 <a href="http://pythonscraping.com" target="_blank" rel="noopener">http://pythonscraping.com</a> 的服务器上 &lt; 网络应用根地址 &gt;/pages 文件夹里的 HTML 文件 page1.html 的源代码。</p>
<h2 id="1-2-BeautifulSoup简介"><a href="#1-2-BeautifulSoup简介" class="headerlink" title="1.2 BeautifulSoup简介"></a>1.2 BeautifulSoup简介</h2><blockquote>
<p>它通过定位 HTML 标签来格式化和组织复杂的网络信息，用简单易用的 Python 对象为我们展现 XML 结构信息。</p>
</blockquote>
<h3 id="1-2-1-安装BeautifulSoup"><a href="#1-2-1-安装BeautifulSoup" class="headerlink" title="1.2.1 安装BeautifulSoup"></a>1.2.1 安装BeautifulSoup</h3><p>由于 BeautifulSoup 库不是 Python 标准库，因此需要单独安装。在本书中，我们将使用最新的 BeautifulSoup 4 版本（也叫 BS4）。BeautifulSoup 4 的所有安装方法都在 <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="noopener">http://www.crummy.com/software/BeautifulSoup/bs4/doc/</a> 里面。</p>
<blockquote>
<p>Linux 系统上的基本安装方法是：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo apt-get install python-bs4</span><br></pre></td></tr></table></figure>

<blockquote>
<p>对于Mac系统，首先用</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo easy_install pip</span><br></pre></td></tr></table></figure>

<blockquote>
<p>安装 Python 的包管理器 pip，然后运行</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$pip install beautifulsoup4</span><br></pre></td></tr></table></figure>

<blockquote>
<p>另外，注意如果你的设备同时安装了 Python 2.x 和 Python 3.x，你需要用 python3 运行Python 3.x：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$python3 myScript.py</span><br></pre></td></tr></table></figure>

<blockquote>
<p>当你安装包的时候，如果有可能安装到了 Python 2.x 而不是 Python 3.x 里，就需要使用：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo python3 setup.py install</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果用 pip 安装，你还可以用 pip3 安装 Python 3.x 版本的包：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$pip3 install beautifulsoup4</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在 Windows 系统上安装与在 Mac 和 Linux 上安装差不多。从上面的下载链接下载最新的BeautifulSoup 4 源代码，解压后进入文件，然后执行：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; python setup.py install</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这样就可以了！ BeautifulSoup 将被当作设备上的一个 Python 库。你可以在 Python 终端里导入它测试一下：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$python</span><br><span class="line">&gt; from bs4 import BeautifulSoup</span><br></pre></td></tr></table></figure>

<p>如果没有错误，说明导入成功了。<br>另外，还有一个 Windows 版 pip（<a href="https://pypi.python.org/pypi/setuptools）" target="_blank" rel="noopener">https://pypi.python.org/pypi/setuptools）</a> 的 .exe 格式安装器 ，装了之后你就可以轻松安装和管理包了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;pip install beautifulsoup4</span><br></pre></td></tr></table></figure>

<h3 id="1-2-2-运行BeautifulSoup"><a href="#1-2-2-运行BeautifulSoup" class="headerlink" title="1.2.2 运行BeautifulSoup"></a>1.2.2 运行BeautifulSoup</h3><blockquote>
<p>BeautifulSoup 库最常用的对象恰好就是 BeautifulSoup 对象。让我们把本章开头的例子调整一下运行看看：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import urlopen</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">html = urlopen(&quot;http://www.pythonscraping.com/pages/page1.html&quot;)</span><br><span class="line">bsObj = BeautifulSoup(html.read())</span><br><span class="line">print(bsObj.h1)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>输出结果是：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;h1&gt;An Interesting Title&lt;/h1&gt;</span><br></pre></td></tr></table></figure>

<p>和前面例子一样，我们导入 urlopen，然后调用 html.read() 获取网页的 HTML 内容。这样就可以把 HTML 内容传到 BeautifulSoup 对象，转换成下面的结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- html &lt;html&gt;&lt;head&gt;...&lt;/head&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;</span><br><span class="line">- head  &lt;head&gt;&lt;title&gt;A Useful Page&lt;title&gt;&lt;/head&gt;</span><br><span class="line">- title  &lt;title&gt;A Useful Page&lt;/title&gt;</span><br><span class="line">- body  &lt;body&gt;&lt;h1&gt;An Int...&lt;/h1&gt;&lt;div&gt;Lorem ip...&lt;/div&gt;&lt;/body&gt;</span><br><span class="line">- h1  &lt;h1&gt;An Interesting Title&lt;/h1&gt;</span><br><span class="line">- div  &lt;div&gt;Lorem Ipsum dolor...&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<p>可以看出，我们从网页中提取的 &lt;h1&gt; 标签被嵌在 BeautifulSoup 对象 bsObj 结构的第二层（html → body → h1）。但是，当我们从对象里提取 h1 标签的时候，可以直接调用它：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bsObj.h1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>其实，下面的所有函数调用都可以产生同样的结果：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bsObj.html.body.h1</span><br><span class="line">bsObj.body.h1</span><br><span class="line">bsObj.html.h1</span><br></pre></td></tr></table></figure>

<p>希望这个例子可以向你展示 BeautifulSoup 库的强大与简单。其实，任何 HTML（或XML）文件的任意节点信息都可以被提取出来，只要目标信息的旁边或附近有标记就行。之后，我们将进一步探讨一些更复杂的 BeautifulSoup 函数，还会介绍正则表达式，以及如何把正则表达式用于 BeautifulSoup 以对网站信息进行提取。</p>
<h3 id="1-2-3-可靠的网络连接"><a href="#1-2-3-可靠的网络连接" class="headerlink" title="1.2.3 可靠的网络连接"></a>1.2.3 可靠的网络连接</h3><p>网络是十分复杂的。网页数据格式不友好，网站服务器宕机，目标数据的标签找不到，都是很麻烦的事情。网络数据采集最痛苦的遭遇之一，就是爬虫运行的时候你洗洗睡了，梦想着明天一早数据就都会采集好放在数据库里，结果第二天醒来，你看到的却是一个因某种数据格式异常导致运行错误的爬虫，在前一天当你不再盯着屏幕去睡觉之后，没过一会儿爬虫就不再运行了。那个时候，你可能想骂发明互联网（以及那些奇葩的网络数据格式）的人，但是你真正应该斥责的人是你自己，为什么一开始不估计可能会出现的异常！</p>
<blockquote>
<p>让我们看看爬虫 import 语句后面的第一行代码，如何处理那里可能出现的异常：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html = urlopen(&quot;http://www.pythonscraping.com/pages/page1.html&quot;)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这行代码主要可能会发生两种异常：</p>
</blockquote>
<ul>
<li>网页在服务器上不存在（或者获取页面的时候出现错误）</li>
<li>服务器不存在<br>第一种异常发生时，程序会返回 HTTP 错误。 HTTP 错误可能是“404 Page Not Found”“500Internal Server Error”等。所有类似情形， urlopen 函数都会抛出“HTTPError”异常。我们可以用下面的方式处理这种异常：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">html = urlopen(&quot;http://www.pythonscraping.com/pages/page1.html&quot;)</span><br><span class="line">except HTTPError as e:</span><br><span class="line">print(e)</span><br><span class="line"># 返回空值，中断程序，或者执行另一个方案</span><br><span class="line">else:</span><br><span class="line"># 程序继续。注意：如果你已经在上面异常捕捉那一段代码里返回或中断（break），</span><br><span class="line"># 那么就不需要使用else语句了，这段代码也不会执行</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果程序返回 HTTP 错误代码，程序就会显示错误内容，不再执行 else 语句后面的代码。</p>
</blockquote>
<p>如果服务器不存在（就是说链接 <a href="http://www.pythonscraping.com/" target="_blank" rel="noopener">http://www.pythonscraping.com/</a> 打不开，或者是 URL 链接写错了）， urlopen 会返回一个 None 对象。这个对象与其他编程语言中的 null 类似。我们可以增加一个判断语句检测返回的 html 是不是 None：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if html is None:</span><br><span class="line">print(&quot;URL is not found&quot;)</span><br><span class="line">else:</span><br><span class="line"># 程序继续</span><br></pre></td></tr></table></figure>

<blockquote>
<p>下面的代码是上面爬虫的另一种写法：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import urlopen</span><br><span class="line">from urllib.error import HTTPError</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">	def getTitle(url):	#创建了一个 getTitle 函数,可以返回网页的标题</span><br><span class="line">		try:</span><br><span class="line">			html = urlopen(url)</span><br><span class="line">		except HTTPError as e: #检查了HTTPError</span><br><span class="line">			return None	#如果获取网页的时候遇到问题就返回一个 None 对象</span><br><span class="line">		try:</span><br><span class="line">			bsObj = BeautifulSoup(html.read()) #这两行中的任何一行有问题</span><br><span class="line">			title = bsObj.body.h1 </span><br><span class="line">		except AttributeError as e: #AttributeError 都可能被抛出异常</span><br><span class="line">			return None</span><br><span class="line">			return title</span><br><span class="line">title = getTitle(&quot;http://www.pythonscraping.com/pages/page1.html&quot;)</span><br><span class="line">if title == None:</span><br><span class="line">	print(&quot;Title could not be found&quot;)</span><br><span class="line">else:</span><br><span class="line">	print(title)</span><br></pre></td></tr></table></figure>
<p>在写爬虫的时候，思考代码的总体格局，让代码既可以捕捉异常又容易阅读，这是很重要的。如果你还希望能够很大程度地重用代码，那么拥有像 getSiteHTML 和 getTitle 这样的通用函数（具有周密的异常处理功能）会让快速稳定地网络数据采集变得简单易行。</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2019/11/17/Python%E7%88%AC%E8%99%AB%E4%BB%8B%E7%BB%8D/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Python爬虫介绍</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>


<div class="ds-share share" data-thread-key="初识Python爬虫" data-title="初识Python爬虫" data-url="http://yoursite.com/2019/11/17/%E5%88%9D%E8%AF%86Python%E7%88%AC%E8%99%AB/"  data-images="https://www.duitang.com/blog/?id=888975090" data-content="初识Python爬虫">
    <div class="ds-share-inline">
      <ul  class="ds-share-icons-16">
      	<li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);" target="_blank" rel="noopener">分享到：</a></li>
        <li><a class="ds-weibo" href="javascript:void(0);" target="_blank" rel="noopener" data-service="weibo">微博</a></li>
        <li><a class="ds-qzone" href="javascript:void(0);" target="_blank" rel="noopener" data-service="qzone">QQ空间</a></li>
        <li><a class="ds-qqt" href="javascript:void(0);" target="_blank" rel="noopener" data-service="qqt">腾讯微博</a></li>
        <li><a class="ds-wechat" href="javascript:void(0);" target="_blank" rel="noopener" data-service="wechat">微信</a></li>
      </ul>
      <div class="ds-share-icons-more">
      </div>
    </div>
 </div>
 





</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2019 fans
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>